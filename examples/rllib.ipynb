{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demonstrating `mobile-env`\n",
    "\n",
    "`mobile-env` is a simple and open environment for training, testing, and evaluating autonomous coordination\n",
    "approaches for wireless mobile networks.\n",
    "\n",
    "* `mobile-env` is written in pure Python and can be installed easily via [PyPI](https://pypi.org/project/mobile-env/)\n",
    "* It allows simulating various scenarios with moving users in a cellular network with multiple base stations\n",
    "* `mobile-env` implements the standard [Gymnasium](https://gymnasium.farama.org/) (previously [OpenAI Gym](https://gym.openai.com/)) interface such that it can be used with all common frameworks for reinforcement learning\n",
    "* `mobile-env` is not restricted to reinforcement learning approaches but can also be used with conventional control approaches or dummy benchmark algorithms\n",
    "* It supports both centralized, single-agent control and distributed, multi-agent control\n",
    "* It can be configured easily (e.g., adjusting number and movement of users, properties of cells, etc.)\n",
    "* It is also easy to extend `mobile-env`, e.g., implementing different observations, actions, or reward\n",
    "\n",
    "As such `mobile-env` is a simple platform to evaluate and compare different coordination approaches in a meaningful way.\n",
    "\n",
    "\n",
    "\n",
    "**Demonstration Steps:**\n",
    "\n",
    "This demonstration consists of the following steps (split accross separate notebooks):\n",
    "\n",
    "1. [Intro notebook](examples\\demo.ipynb): Installation and usage of `mobile-env` with dummy actions\n",
    "2. [Intro notebook](examples\\demo.ipynb): Configuration of `mobile-env` and adjustment of the observation space (optional)\n",
    "3. [SB3 notebook](examples\\sb3.ipynb): Training a single-agent reinforcement learning approach with [`stable-baselines3`](https://github.com/DLR-RM/stable-baselines3)\n",
    "4. **This notebook:** Training a multi-agent reinforcement learning approach with [Ray RLlib](https://docs.ray.io/en/latest/rllib.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Agent RL with Ray RLlib\n",
    "\n",
    "As alternative to controlling cell selection centrally for all users from a single RL agent, we can also use multi-agent RL, i.e., delegating control to multiple agents that act in parallel.\n",
    "As an example, we could have each RL agent responsible for the cell selection of a single user. Then we would need as many agents as we have users.\n",
    "That's what happens in the predefined multi-agent scenarios, e.g., `mobile-small-ma-v0`.\n",
    "\n",
    "Let's use RLlib to train a multi-agent policy on the `mobile-small-ma-v0` scenario, which has three base stations and five users.\n",
    "\n",
    "### Set up Ray RLlib\n",
    "\n",
    "To train a multi-agent approach, we can use Ray RLlib, which supports multi-agent RL out of the box. To register the predefined multi-agent scenario with RLlib, `mobile-env` provides a wrapper `RLlibMAWrapper`. But first we need to install `mobile-env` and `ray` with RLlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mobile-env in c:\\users\\stbs\\projects\\mobile-env (2.0.1)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (0.26.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (3.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (2.0.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (2.3.0)\n",
      "Requirement already satisfied: shapely in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from mobile-env) (2.0.1)\n",
      "Requirement already satisfied: svgpath2mpl in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\svgpath2mpl-1.0.0-py3.8.egg (from mobile-env) (1.0.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from gymnasium->mobile-env) (0.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from gymnasium->mobile-env) (6.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\cloudpickle-2.2.1-py3.8.egg (from gymnasium->mobile-env) (2.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\fonttools-4.39.2-py3.8.egg (from matplotlib->mobile-env) (4.39.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\pillow-9.4.0-py3.8-win-amd64.egg (from matplotlib->mobile-env) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from matplotlib->mobile-env) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\cycler-0.11.0-py3.8.egg (from matplotlib->mobile-env) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from matplotlib->mobile-env) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\kiwisolver-1.4.4-py3.8-win-amd64.egg (from matplotlib->mobile-env) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\pyparsing-3.1.0a1-py3.8.egg (from matplotlib->mobile-env) (3.1.0a1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from matplotlib->mobile-env) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from matplotlib->mobile-env) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from pandas->mobile-env) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from pandas->mobile-env) (2023.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium->mobile-env) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mobile-env) (1.16.0)\n",
      "Requirement already satisfied: ray[rllib]==2.5.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: tensorflow-probability in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (3.12.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.0.5)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.3.3)\n",
      "Requirement already satisfied: grpcio<=1.51.3,>=1.32.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.51.3)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (2.29.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (6.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (8.1.3)\n",
      "Requirement already satisfied: attrs in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (23.1.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.23.5)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (3.20.3)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (4.17.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (2.0.1)\n",
      "Requirement already satisfied: lz4 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (4.3.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (0.20.0)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (6.0.1)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (0.1.8)\n",
      "Requirement already satisfied: typer in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (0.7.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (1.9.1)\n",
      "Requirement already satisfied: gymnasium==0.26.3 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (0.26.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (2.6)\n",
      "Requirement already satisfied: rich in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from ray[rllib]==2.5.1) (13.3.5)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from gymnasium==0.26.3->ray[rllib]==2.5.1) (0.0.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\cloudpickle-2.2.1-py3.8.egg (from gymnasium==0.26.3->ray[rllib]==2.5.1) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from gymnasium==0.26.3->ray[rllib]==2.5.1) (6.1.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from tensorflow-probability) (1.4.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from tensorflow-probability) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from click>=7.0->ray[rllib]==2.5.1) (0.4.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from jsonschema->ray[rllib]==2.5.1) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from jsonschema->ray[rllib]==2.5.1) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from jsonschema->ray[rllib]==2.5.1) (5.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from pandas->ray[rllib]==2.5.1) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from pandas->ray[rllib]==2.5.1) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from pandas->ray[rllib]==2.5.1) (2022.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from requests->ray[rllib]==2.5.1) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from requests->ray[rllib]==2.5.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from requests->ray[rllib]==2.5.1) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from requests->ray[rllib]==2.5.1) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from rich->ray[rllib]==2.5.1) (4.5.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from rich->ray[rllib]==2.5.1) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from rich->ray[rllib]==2.5.1) (2.2.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from scikit-image->ray[rllib]==2.5.1) (0.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from scikit-image->ray[rllib]==2.5.1) (2.28.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from scikit-image->ray[rllib]==2.5.1) (3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from scikit-image->ray[rllib]==2.5.1) (1.4.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\pillow-9.4.0-py3.8-win-amd64.egg (from scikit-image->ray[rllib]==2.5.1) (9.4.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from scikit-image->ray[rllib]==2.5.1) (2023.4.12)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium==0.26.3->ray[rllib]==2.5.1) (3.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->ray[rllib]==2.5.1) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# install mobile-env\n",
    "!pip install -U mobile-env\n",
    "# install ray RLlib\n",
    "!pip install ray[rllib]==2.5.1 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# use the mobile-env RLlib wrapper for RLlib\n",
    "def register(config):\n",
    "    # importing mobile_env registers the included environments\n",
    "    import mobile_env\n",
    "    from mobile_env.wrappers.multi_agent import RLlibMAWrapper\n",
    "\n",
    "    env = gymnasium.make(\"mobile-small-ma-v0\")\n",
    "    return RLlibMAWrapper(env)\n",
    "\n",
    "# register the predefined scenario with RLlib\n",
    "register_env(\"mobile-small-ma-v0\", register)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a PPO Multi-Agent Policy\n",
    "\n",
    "Now, that the predefined scenario is registered with RLlib, we can configure and train a multi-agent PPO approach on the scenario with RLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 19:24:07,872\tINFO worker.py:1636 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.5.1</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.16', ray_version='2.5.1', ray_commit='a03efd9931128d387649dd48b0e4864b43d3bfb4', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:65505', 'raylet_socket_name': 'tcp://127.0.0.1:64831', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\stbs\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-07-20_19-24-03_196877_11904', 'metrics_export_port': 64853, 'gcs_address': '127.0.0.1:65223', 'address': '127.0.0.1:65223', 'dashboard_agent_listen_port': 52365, 'node_id': '46f13ecaf623308bb38a5d69db1f88537a23a2d810321b72bd7cb604'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "# init ray with available CPUs (and GPUs) and init ray\n",
    "ray.init(\n",
    "  num_cpus=2,   # change to your available number of CPUs\n",
    "  include_dashboard=False,\n",
    "  ignore_reinit_error=True,\n",
    "  log_to_driver=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stbs\\.conda\\envs\\mobile-env\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "2023-07-20 19:25:06,719\tWARNING syncer.py:222 -- You are using remote storage, but you don't have `fsspec` installed. This can lead to inefficient syncing behavior. To avoid this, install fsspec with `pip install fsspec`. Depending on your remote storage provider, consider installing the respective fsspec-package (see https://github.com/fsspec).\n",
      "2023-07-20 19:25:06,737\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/a3c/a3c.py` has been deprecated. Use `rllib_contrib/a3c/` instead. This will raise an error in the future!\n",
      "2023-07-20 19:25:06,739\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/a3c/a3c.py` has been deprecated. Use `rllib_contrib/a3c/` instead. This will raise an error in the future!\n",
      "2023-07-20 19:25:07,183\tWARNING deprecation.py:50 -- DeprecationWarning: `rllib/algorithms/maml/maml.py` has been deprecated. Use `rllib_contrib/maml/` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-20 19:27:03</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:56.23        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.5/7.9 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_mobile-small-ma-v0_5f1f2_00000</td><td>TERMINATED</td><td>127.0.0.1:8360</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          79.252</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\"> -186.81</td><td style=\"text-align: right;\">            -19.9275</td><td style=\"text-align: right;\">            -322.086</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                             </th><th>counters                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>hostname   </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max                   </th><th>policy_reward_mean                    </th><th>policy_reward_min                    </th><th>sampler_perf                                                                                                                                                                                                  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                        </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_mobile-small-ma-v0_5f1f2_00000</td><td style=\"text-align: right;\">                  20000</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009922981262207031, &#x27;StateBufferConnector_ms&#x27;: 0.017557144165039062, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.5606132745742798}</td><td>{&#x27;num_env_steps_sampled&#x27;: 4000, &#x27;num_env_steps_trained&#x27;: 4000, &#x27;num_agent_steps_sampled&#x27;: 20000, &#x27;num_agent_steps_trained&#x27;: 20000}</td><td>{}              </td><td>2023-07-20_19-27-03</td><td>True  </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">            -19.9275</td><td style=\"text-align: right;\">              -186.81</td><td style=\"text-align: right;\">            -322.086</td><td style=\"text-align: right;\">                  40</td><td style=\"text-align: right;\">              40</td><td>Lenovo-Yoga</td><td>{&#x27;learner&#x27;: {&#x27;shared_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 1.7262574494960707, &#x27;cur_kl_coeff&#x27;: 0.2, &#x27;cur_lr&#x27;: 5.0000000000000016e-05, &#x27;total_loss&#x27;: 8.068133396302565, &#x27;policy_loss&#x27;: -0.006108309560398039, &#x27;vf_loss&#x27;: 8.072629420266283, &#x27;vf_explained_var&#x27;: 0.03875742717913002, &#x27;kl&#x27;: 0.008061309833623109, &#x27;entropy&#x27;: 1.3782111626268698, &#x27;entropy_coeff&#x27;: 0.0}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 127.38853503184713, &#x27;num_grad_updates_lifetime&#x27;: 2355.5, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2354.5}}, &#x27;num_env_steps_sampled&#x27;: 4000, &#x27;num_env_steps_trained&#x27;: 4000, &#x27;num_agent_steps_sampled&#x27;: 20000, &#x27;num_agent_steps_trained&#x27;: 20000}</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">                    20000</td><td style=\"text-align: right;\">                    20000</td><td style=\"text-align: right;\">                   4000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   50.4775</td><td style=\"text-align: right;\">                   4000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   50.4775</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: 12.044144144144147, &#x27;ram_util_percent&#x27;: 95.96396396396395}</td><td style=\"text-align: right;\"> 8360</td><td>{&#x27;shared_policy&#x27;: 4.675273777830706}</td><td>{&#x27;shared_policy&#x27;: -37.361940196467856}</td><td>{&#x27;shared_policy&#x27;: -88.18277678648225}</td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.5595255420077476, &#x27;mean_inference_ms&#x27;: 1.6059204507726217, &#x27;mean_action_processing_ms&#x27;: 0.5598039038328492, &#x27;mean_env_wait_ms&#x27;: 4.779515639450276, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -19.92746997992103, &#x27;episode_reward_min&#x27;: -322.08627121618844, &#x27;episode_reward_mean&#x27;: -186.80970098233928, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 40, &#x27;policy_reward_min&#x27;: {&#x27;shared_policy&#x27;: -88.18277678648225}, &#x27;policy_reward_max&#x27;: {&#x27;shared_policy&#x27;: 4.675273777830706}, &#x27;policy_reward_mean&#x27;: {&#x27;shared_policy&#x27;: -37.361940196467856}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-322.08627121618844, -278.88043273685696, -244.71452134426957, -157.1398199851625, -226.00008248822994, -127.82212125721367, -247.46025302073042, -257.3566577006891, -133.04203355210132, -149.52059947456613, -182.438737363085, -241.57087379202846, -170.4377571697119, -121.6072213233723, -182.68594830964847, -146.65869909088593, -238.49180030595232, -255.82750090110454, -233.46191958283333, -179.84368864482855, -105.85947426307229, -19.92746997992103, -192.80547659971486, -223.2493490739629, -273.18700857570707, -263.77550289439387, -168.87990934096985, -136.695985086413, -146.67970252124113, -135.82812894511898, -160.92218828762213, -297.73169168607154, -138.04634050338998, -172.98576266494652, -118.69265622866148, -217.94240718709767, -137.81712412032542, -156.48512154158567, -157.6607284950749, -150.16907203882303], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], &#x27;policy_shared_policy_reward&#x27;: [-51.03341555916889, -57.961168201249535, -86.27784871536005, -86.53046436582014, -40.28337437458947, -87.53273695951005, -52.2755688861878, -36.02495286799379, -40.76561525830208, -62.281558764863185, -82.44604476729212, -34.02371393362752, -36.399994293918915, -42.66165418643358, -49.183114162997676, -34.034125265869314, -46.009601709386736, -24.859928935665824, -30.208717797039135, -22.027446277201392, -60.14757318147146, -56.331820379281886, -18.166686981568873, -75.85201666228218, -15.50198528362532, -12.455061576705978, -14.373400166844698, -22.213580141926005, -20.16427189751852, -58.61580747421852, -68.2088450596716, -33.056791745049814, -29.637188375052308, -35.424567329912776, -81.132860511044, -51.058680682076364, -56.58453598079767, -80.15906395012463, -31.772688219735898, -37.78168886795459, -45.27446513983769, -32.30007349540072, -20.29210634747012, -15.130006274654102, -20.045382294738598, -24.163608709756048, -12.460561264070085, -72.57612503656794, -26.984221673562477, -13.336082790609444, -36.9330626965723, -25.092718373651014, -77.4418783505646, -17.931666039823234, -25.039411902473628, -50.816740110514864, -36.576772643198545, -71.1066833952199, -57.1363211926676, -25.934356450427806, -37.971759666559315, -37.245302660083325, -38.80022523590413, -29.10069466114797, -27.31977494601717, -25.728506022501787, -29.9740757257651, -13.457002634443738, -22.42210645072346, -30.02553048993827, -38.80174235164709, -44.046277373610316, -33.73957762558036, -48.951797258118916, -17.146553700692017, -27.317654298552483, -28.94077680953367, -47.7845058544837, -23.579967043085187, -19.035795085230863, -58.39275077343285, -53.33509819310671, -50.494009313187085, -23.864957848002263, -52.40498417822365, -80.70090586558031, -45.383854489720726, -34.9172578939934, -37.68242263602946, -57.14306001578048, -88.18277678648225, -22.876761032773896, -44.859941845811065, -38.58898396749046, -38.95345595027577, -43.59238297343855, -24.97134999998932, -38.98054125502674, -46.78411049111446, -25.51530392525937, -34.136957260460406, -44.59221878475209, -25.64617233716315, -0.35380283793888495, -1.1303230427577367, -7.160823786436596, -1.5843416241190953, -10.11357388748882, 4.675273777830706, -5.744004459707221, -22.71933535229186, -37.3720261869451, -50.237301215606394, -38.40361234352491, -44.07320150134653, -33.402427020416525, -22.760754192079247, -43.9937320647077, -73.2187353464703, -49.873700450289164, -76.8252085026487, -37.409042643384815, -74.95429481269328, -41.20761704440594, -42.790845572574355, -37.54137347761333, -58.086859076842174, -33.541527565204234, -60.94995866692314, -73.65578410781116, -38.616031202062416, -49.47301009468382, -20.162834960833145, -36.16367660990922, -24.46435647348106, -43.13530714973844, -17.99899348663194, -23.699378509025472, -38.08455127054142, -13.777754670475838, -18.980538050814424, -27.827378510896153, -24.005600654926372, -40.169563812790635, -35.69662149181359, -38.473849235679104, -41.745383634431946, -12.767212127818915, -26.443391536468457, -16.398292410720526, -33.117156986057296, -22.861624981924084, -79.12030876658399, -19.569112370424193, -6.253985182632566, -55.79808659143144, -61.38525122592956, -66.671589144198, -57.28257219220108, -56.59419253231149, -32.704019993210714, -61.00148856730766, -15.049110236276697, -13.224430677461868, -16.0672910291331, -26.889657979185074, -56.21120486872933, -57.48167758466561, -15.891080664778913, -16.512141567587545, -13.878121038126732, -19.79864980917352, -25.52023197897797, -36.16750987593207, -23.32814352645112, -70.7339254202731, -31.331027436007506, -39.98630731081323, -33.174696522266885, -42.716450497737085, -34.98299711830303, -21.983077604514445, -27.29889449005229, -23.503828362820443, -30.048326544635124, -48.99666102493343, -40.2410176628139, -24.831721725962062, -13.8038356176105, -28.61188551026558, -32.96058666102843, -30.401647361356673, -55.384367765768225, -21.071139920560817, -17.84298678636094, -21.238318467487318, -51.78797889605226, -31.934300571798197, -32.048347756155096, -13.1601263473302]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.5595255420077476, &#x27;mean_inference_ms&#x27;: 1.6059204507726217, &#x27;mean_action_processing_ms&#x27;: 0.5598039038328492, &#x27;mean_env_wait_ms&#x27;: 4.779515639450276, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.009922981262207031, &#x27;StateBufferConnector_ms&#x27;: 0.017557144165039062, &#x27;ViewRequirementAgentConnector_ms&#x27;: 0.5606132745742798}}</td><td style=\"text-align: right;\">              79.252</td><td style=\"text-align: right;\">            79.252</td><td style=\"text-align: right;\">        79.252</td><td>{&#x27;training_iteration_time_ms&#x27;: 79243.155, &#x27;sample_time_ms&#x27;: 34188.102, &#x27;learn_time_ms&#x27;: 45049.352, &#x27;learn_throughput&#x27;: 88.792, &#x27;synch_weights_time_ms&#x27;: 2.001}</td><td style=\"text-align: right;\"> 1689874023</td><td style=\"text-align: right;\">             4000</td><td style=\"text-align: right;\">                   1</td><td>5f1f2_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 19:27:03,902\tINFO tune.py:1111 -- Total run time: 117.18 seconds (115.89 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray.air\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.stopper import MaximumIterationStopper\n",
    "\n",
    "# Create an RLlib config using multi-agent PPO on mobile-env's small scenario.\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"mobile-small-ma-v0\")\n",
    "    # Here, we configure all agents to share the same policy.\n",
    "    .multi_agent(\n",
    "        policies={\"shared_policy\": PolicySpec()},\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"shared_policy\",\n",
    "    )\n",
    "    # RLlib needs +1 CPU than configured below (for the driver/traininer?)\n",
    "    .resources(num_cpus_per_worker=1)\n",
    "    .rollouts(num_rollout_workers=1)\n",
    ")\n",
    "\n",
    "# Create the Trainer/Tuner and define how long to train\n",
    "tuner = ray.tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=ray.air.RunConfig(\n",
    "        # Save the training progress and checkpoints locally under the specified subfolder.\n",
    "        storage_path=\"./results_rllib\",\n",
    "        # Control training length by setting the number of iterations. 1 iter = 4000 time steps by default.\n",
    "        stop=MaximumIterationStopper(max_iter=10),\n",
    "        checkpoint_config=ray.air.CheckpointConfig(checkpoint_at_end=True),\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "# Run training and save the result\n",
    "result_grid = tuner.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the learning curve on TensorBoard. The corresponding files are in the configured `save_dir=results_rllib`.\n",
    "\n",
    "The \"episode_reward_mean\" should increase with increasing training, indicating that the agent is learning. RLlib also logs many other metrics by default, which can be useful for debugging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17908), started 0:00:22 ago. (Use '!kill 17908' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c7f9a32b7de9f889\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c7f9a32b7de9f889\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir results_rllib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Test the Trained Multi-Agent Policy\n",
    "\n",
    "Let's load the trained multi-agent model and visualize the learned multi-agent policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 19:29:26,871\tINFO trainable.py:173 -- Trainable.setup took 14.657 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-07-20 19:29:26,881\tWARNING util.py:68 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "\n",
    "# load the trained agent from the stored checkpoint\n",
    "best_result = result_grid.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "ppo = Algorithm.from_checkpoint(best_result.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: -0.08314402193659076, 1: -0.06218562828460161, 2: -1.0, 3: -1.0, 4: -0.15216507928783843}\n"
     ]
    }
   ],
   "source": [
    "import mobile_env\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# create the env for testing\n",
    "# pass rgb_array as render mode so the env can be rendered inside the notebook\n",
    "env = gymnasium.make(\"mobile-small-ma-v0\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "# run one episode with the trained model\n",
    "while not done:\n",
    "    # gather action from each actor (for each UE)\n",
    "    action = {}\n",
    "    for agent_id, agent_obs in obs.items():\n",
    "        # compute the action for the given agent using the shared policy\n",
    "        action[agent_id] = ppo.compute_single_action(agent_obs, policy_id=\"shared_policy\")\n",
    "\n",
    "    # apply actions and perform step on simulation environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    # render environment as RGB\n",
    "    plt.imshow(env.render())\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the learned policy is not yet perfect (the reward is still increasing, i.e., agent is still learning), the visualization shows that most users are connected to suitable cells.\n",
    "\n",
    "Feel free to experiment more with `mobile-env`, e.g., by training longer or customizing the environment.\n",
    "The [documentation](https://mobile-env.readthedocs.io/en/latest/) provides further information about the API.\n",
    "If you still have open questions or run into issues, you can [open an issue on GitHub](https://github.com/stefanbschneider/mobile-env/issues).\n",
    "\n",
    "We hope `mobile-env` is useful for you. If you use `mobile-env`, please cite it and let us know - then we can list your work on `mobile-env`'s Readme.\n",
    "We also very much appreciate contributions in the form of pull requests.\n",
    "\n",
    "```\n",
    "@inproceedings{schneider2022mobileenv,\n",
    "  author = {Schneider, Stefan and Werner, Stefan and Khalili, Ramin and Hecker, Artur and Karl, Holger},\n",
    "  title = {mobile-env: An Open Platform for Reinforcement Learning in Wireless Mobile Networks},\n",
    "  booktitle={Network Operations and Management Symposium (NOMS)},\n",
    "  year = {2022},\n",
    "  publisher = {IEEE/IFIP},\n",
    "}\n",
    "```\n",
    "\n",
    "Happy training/learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
